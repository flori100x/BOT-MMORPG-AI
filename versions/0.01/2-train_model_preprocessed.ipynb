{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b2412fa",
   "metadata": {},
   "source": [
    "# Part 2 -  Model creation\n",
    "In this part we are going to create the neural network model and train."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81d16c3",
   "metadata": {},
   "source": [
    "## Loding Libraries\n",
    "Here we load the common libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffdf790b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda3\\envs\\pygta5\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from grabscreen import grab_screen\n",
    "import cv2\n",
    "#import tdqm\n",
    "import os\n",
    "import pandas as pd\n",
    "#from tqdm import tqdm\n",
    "from collections import deque\n",
    "from models import inception_v3 as googlenet\n",
    "from models import alexnet2\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0ee8cb",
   "metadata": {},
   "source": [
    "# Analysis of the Input file\n",
    "We are going to analize the files  that we have created in the part 1\n",
    "Let us first select the first created file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4238a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessed image rgb color - no image filters\n",
    "file_name = \"preprocessed_training_data-1.npy\"\n",
    "#file_name = \"training_data-1.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0a59322",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Processed image single color\n",
    "#file_name = \"processed_training_data-1.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73004842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full file info\n",
    "train_data = np.load(file_name,allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9da3f74f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This file has the following shape\n",
    "train_data.shape\n",
    "#(500, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7997a882",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa23667d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27397379",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95c6a990",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_data[:-50]\n",
    "test = train_data[-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93228876",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fb0f139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape\n",
    "#(50, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d93ede5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape\n",
    "#(450, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab342b78",
   "metadata": {},
   "source": [
    "We begin the train part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818b79cc",
   "metadata": {},
   "source": [
    "## Train Image part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7eb7a282",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_image = np.array([i[0] for i in train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b76b9e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450, 270, 480, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_image.shape\n",
    "#(450, 270, 480, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e9a87da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_image[449][269][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b30723d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(450, 270, 480, 3)  We choose only the imagen part of the train data, \n",
    "#There are 450 picturtes with resolutionn WIDTH = 480 and HEIGHT = 270 with 3 colors rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df9790fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We perform the reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc1d9da",
   "metadata": {},
   "source": [
    "numpy.reshape(a, newshape, order='C')\n",
    "\n",
    "- a - Array to be reshaped.\n",
    "- newshape  - The new shape should be compatible with the original shape.\n",
    "\n",
    "- order- Read the elements of a using this index order, and place the elements into the reshaped array using this index order.\n",
    "\n",
    "Gives a new shape to an array without changing its data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98b91110",
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH = 480\n",
    "HEIGHT = 270"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e410f6bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450, 480, 270, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For preprocessed rgb\n",
    "X=X_image.reshape(-1,WIDTH,HEIGHT,3)\n",
    "X.shape\n",
    "#(450, 480, 270, 3) For 3 colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ca0bdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For processed uone color\n",
    "#X=X_image.reshape(-1,WIDTH,HEIGHT,1)\n",
    "#X.shape\n",
    "#(450, 480, 270, 1) For one color"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05f6920",
   "metadata": {},
   "source": [
    "## Train Input part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab2ac7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = [i[1] for i in train]\n",
    "#Z = [i[2] for i in train]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83302254",
   "metadata": {},
   "source": [
    "We begin the test part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32df747",
   "metadata": {},
   "source": [
    "## Test Image part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba76f3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = np.array([i[0] for i in test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90b6e32c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "628261f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 270, 480, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image.shape\n",
    "#(50, 270, 480, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6509d5",
   "metadata": {},
   "source": [
    "numpy.reshape(a, newshape, order='C')\n",
    "\n",
    "- a - Array to be reshaped.\n",
    "- newshape  - The new shape should be compatible with the original shape.\n",
    "\n",
    "- order- Read the elements of a using this index order, and place the elements into the reshaped array using this index order.\n",
    "\n",
    "Gives a new shape to an array without changing its data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da418c0",
   "metadata": {},
   "source": [
    "TODO We have to understand why I was 3 in order in reshape(-1,WIDTH,HEIGHT,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "132ae517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 480, 270, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For Preprocessed\n",
    "test_x=test_image.reshape(-1,WIDTH,HEIGHT,3)\n",
    "test_x.shape\n",
    "#(50, 480, 270, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a2de8e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Processed\n",
    "#test_x=test_image.reshape(-1,WIDTH,HEIGHT,1)\n",
    "#test_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa78ed0",
   "metadata": {},
   "source": [
    "## Test Input part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88f352d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = [i[1] for i in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ba0a5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FILE_I_END = 1860\n",
    "FILE_I_END = 2\n",
    "WIDTH = 480\n",
    "HEIGHT = 270\n",
    "LR = 1e-3\n",
    "#EPOCHS = 30\n",
    "EPOCHS = 1\n",
    "MODEL_NAME = 'model/test'\n",
    "PREV_MODEL = ''\n",
    "LOAD_MODEL = True\n",
    "\n",
    "wl = 0\n",
    "sl = 0\n",
    "al = 0\n",
    "dl = 0\n",
    "\n",
    "wal = 0\n",
    "wdl = 0\n",
    "sal = 0\n",
    "sdl = 0\n",
    "nkl = 0\n",
    "\n",
    "w = [1,0,0,0,0,0,0,0,0]\n",
    "s = [0,1,0,0,0,0,0,0,0]\n",
    "a = [0,0,1,0,0,0,0,0,0]\n",
    "d = [0,0,0,1,0,0,0,0,0]\n",
    "wa = [0,0,0,0,1,0,0,0,0]\n",
    "wd = [0,0,0,0,0,1,0,0,0]\n",
    "sa = [0,0,0,0,0,0,1,0,0]\n",
    "sd = [0,0,0,0,0,0,0,1,0]\n",
    "nk = [0,0,0,0,0,0,0,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "36bf9e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nk )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "629f7e37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model = googlenet(WIDTH, HEIGHT, 3, LR, output=9, model_name=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "32de1d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "size=[    0,     0,     0,     0,     0,     0,     0,     0,     1,\n",
    "                   0,     0,  4638, 32365,  1218, -1516,     0,     0,     0,\n",
    "                   0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "                   0,     0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f479433d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9684229f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda3\\envs\\pygta5\\lib\\site-packages\\tflearn\\initializations.py:110: calling UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\envs\\pygta5\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:552: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\envs\\pygta5\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1096: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\envs\\pygta5\\lib\\site-packages\\tflearn\\initializations.py:165: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model = googlenet(WIDTH, HEIGHT, 3, LR, output=29, model_name=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f9bc4ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 7  | total loss: \u001b[1m\u001b[32m23581.80273\u001b[0m\u001b[0m | time: 19.940s\n",
      "| Momentum | epoch: 001 | loss: 23581.80273 - acc: 0.7515 -- iter: 448/450\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32m412.41016\u001b[0m\u001b[0m | time: 26.774s\n",
      "| Momentum | epoch: 001 | loss: 412.41016 - acc: 0.8649 | val_loss: -56904.23828 - val_acc: 1.0000 -- iter: 450/450\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "model.fit({'input': X}, \n",
    "          {'targets': Y}, \n",
    "          n_epoch=1, \n",
    "          validation_set=({'input': test_x},{'targets': test_y}), \n",
    "          snapshot_step=2500, \n",
    "          show_metric=True, \n",
    "          run_id=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0590311d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "def restartkernel() :\n",
    "    display_html(\"<script>Jupyter.notebook.kernel.restart()</script>\",raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b222a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "restartkernel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2889fd6",
   "metadata": {},
   "source": [
    "## Full code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49c5b932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 15  | total loss: \u001b[1m\u001b[32m-33132.85938\u001b[0m\u001b[0m | time: 9.224s\n",
      "| Momentum | epoch: 002 | loss: -33132.85938 - acc: 0.9376 -- iter: 448/450\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32m-37728.78906\u001b[0m\u001b[0m | time: 10.318s\n",
      "| Momentum | epoch: 002 | loss: -37728.78906 - acc: 0.9551 | val_loss: -104377.50781 - val_acc: 1.0000 -- iter: 450/450\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from grabscreen import grab_screen\n",
    "import cv2\n",
    "#import tdqm\n",
    "import os\n",
    "import pandas as pd\n",
    "#from tqdm import tqdm\n",
    "from collections import deque\n",
    "from models import inception_v3 as googlenet\n",
    "from models import alexnet2\n",
    "from random import shuffle\n",
    "\n",
    "#FILE_I_END = 1860\n",
    "FILE_I_END = 2\n",
    "WIDTH = 480\n",
    "HEIGHT = 270\n",
    "LR = 1e-3\n",
    "#EPOCHS = 30\n",
    "EPOCHS = 1\n",
    "MODEL_NAME = 'model/test'\n",
    "PREV_MODEL = ''\n",
    "LOAD_MODEL = False\n",
    "\n",
    "wl = 0\n",
    "sl = 0\n",
    "al = 0\n",
    "dl = 0\n",
    "\n",
    "wal = 0\n",
    "wdl = 0\n",
    "sal = 0\n",
    "sdl = 0\n",
    "nkl = 0\n",
    "\n",
    "w = [1,0,0,0,0,0,0,0,0]\n",
    "s = [0,1,0,0,0,0,0,0,0]\n",
    "a = [0,0,1,0,0,0,0,0,0]\n",
    "d = [0,0,0,1,0,0,0,0,0]\n",
    "wa = [0,0,0,0,1,0,0,0,0]\n",
    "wd = [0,0,0,0,0,1,0,0,0]\n",
    "sa = [0,0,0,0,0,0,1,0,0]\n",
    "sd = [0,0,0,0,0,0,0,1,0]\n",
    "nk = [0,0,0,0,0,0,0,0,1]\n",
    "model = googlenet(WIDTH, HEIGHT, 3, LR, output=29, model_name=MODEL_NAME)\n",
    "if LOAD_MODEL:\n",
    "    model.load(PREV_MODEL)\n",
    "    print('We have loaded a previous model!!!!')\n",
    "# iterates through the training files\n",
    "for e in range(EPOCHS):\n",
    "    data_order = [i for i in range(1,FILE_I_END+1)]\n",
    "    shuffle(data_order)\n",
    "    for count,i in enumerate(data_order):\n",
    "        try:\n",
    "            #Preprocessed image rgb color - no image filters\n",
    "            file_name = 'preprocessed_training_data-{}.npy'.format(i)\n",
    "            # full file info\n",
    "            train_data = np.load(file_name,allow_pickle=True)\n",
    "            train = train_data[:-50]\n",
    "            test = train_data[-50:]\n",
    "            X_image = np.array([i[0] for i in train])\n",
    "            # For preprocessed rgb\n",
    "            X=X_image.reshape(-1,WIDTH,HEIGHT,3)\n",
    "            Y = [i[1] for i in train]\n",
    "            test_image = np.array([i[0] for i in test])\n",
    "            #For Preprocessed\n",
    "            test_x=test_image.reshape(-1,WIDTH,HEIGHT,3)\n",
    "            test_y = [i[1] for i in test]           \n",
    "            model.fit({'input': X}, \n",
    "                      {'targets': Y}, \n",
    "                      n_epoch=1, \n",
    "                      validation_set=({'input': test_x},{'targets': test_y}), \n",
    "                      snapshot_step=2500, \n",
    "                      show_metric=True, \n",
    "                      run_id=MODEL_NAME)\n",
    "            if count%10 == 0:\n",
    "                print('SAVING MODEL!')\n",
    "                model.save(MODEL_NAME)                  \n",
    "        except Exception as e:\n",
    "            print(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16067fea",
   "metadata": {},
   "source": [
    "## Alternative Approaches\n",
    "In this notebook we have used InceptionV3, however it is possible use differnet available  popular neural networks.\n",
    "Taking into account Keras, In deep learning models there are some applications available alongside pre-trained weights. These models can be used for prediction, feature extraction, and fine-tuning.\n",
    "\n",
    "Weights are downloaded automatically when instantiating a model. They are stored at ~/.keras/models/.\n",
    "\n",
    "Upon instantiation, the models will be built according to the image data format set in your Keras configuration file at ~/.keras/keras.json. For instance, if you have set image_data_format=channels_last, then any model loaded from this repository will get built according to the TensorFlow data format convention, \"Height-Width-Depth\".\n",
    "\n",
    "Available models\n",
    "Model\tSize (MB)\tTop-1 Accuracy\tTop-5 Accuracy\tParameters\tDepth\tTime (ms) per inference step (CPU)\tTime (ms) per inference step (GPU)\n",
    "- Xception\t88\t79.0%\t94.5%\t22.9M\t81\t109.4\t8.1\n",
    "- VGG16\t528\t71.3%\t90.1%\t138.4M\t16\t69.5\t4.2\n",
    "- VGG19\t549\t71.3%\t90.0%\t143.7M\t19\t84.8\t4.4\n",
    "- ResNet50\t98\t74.9%\t92.1%\t25.6M\t107\t58.2\t4.6\n",
    "- ResNet50V2\t98\t76.0%\t93.0%\t25.6M\t103\t45.6\t4.4\n",
    "- ResNet101\t171\t76.4%\t92.8%\t44.7M\t209\t89.6\t5.2\n",
    "- ResNet101V2\t171\t77.2%\t93.8%\t44.7M\t205\t72.7\t5.4\n",
    "- ResNet152\t232\t76.6%\t93.1%\t60.4M\t311\t127.4\t6.5\n",
    "- ResNet152V2\t232\t78.0%\t94.2%\t60.4M\t307\t107.5\t6.6\n",
    "- InceptionV3\t92\t77.9%\t93.7%\t23.9M\t189\t42.2\t6.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6089e32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pygta5)",
   "language": "python",
   "name": "pygta5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
