{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b2412fa",
   "metadata": {},
   "source": [
    "# Part 2 -  Model creation\n",
    "In this part we are going to create the neural network model and train. \n",
    "With respect to the preprocessed version, we takes the cleaned part 2-Cleaning-Data.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81d16c3",
   "metadata": {},
   "source": [
    "## Loding Libraries\n",
    "Here we load the common libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffdf790b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from grabscreen import grab_screen\n",
    "import cv2\n",
    "#import tdqm\n",
    "import os\n",
    "import pandas as pd\n",
    "#from tqdm import tqdm\n",
    "from collections import deque\n",
    "from models import inception_v3 as googlenet\n",
    "from models import alexnet2\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0ee8cb",
   "metadata": {},
   "source": [
    "# Cleaning of the Input file\n",
    "We are going to analize the files and clean  that we have created in the part 1\n",
    "Let us first select the first created file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4238a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_training_data=pd.read_pickle('clean/data/x_training_data.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9da3f74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_training_data=pd.read_csv('clean/data/y_training_data.csv')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fcacb3",
   "metadata": {},
   "source": [
    "There are 29 input componentes for each frame, we can plot the histogram for each component"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a42cf35",
   "metadata": {},
   "source": [
    "we can create the function that convert the dataframe row to numpy image array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67d7267e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_numpy_image(df_image_clean,index):\n",
    "    #select the row with index label 'index'\n",
    "    image_clean=df_image_clean.loc[[index]].T.to_numpy()\n",
    "    lists =image_clean.tolist()\n",
    "    # Nested List Comprehension to flatten a given 2-D matrix\n",
    "    # 2-D List\n",
    "    matrix = lists\n",
    "    flatten_matrix = [val.tolist() for sublist in matrix for val in sublist]\n",
    "    # converting list to array\n",
    "    arr = np.array(flatten_matrix)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c4bbaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_clean = x_training_data\n",
    "df =y_training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6015fb5",
   "metadata": {},
   "source": [
    "## Creation of train and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ae9820a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We verify that the dimensions are the same\n",
    "assert len(df) == len(df_image_clean), \"The dimensions are not equal, something is wrong \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebd82e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93228876",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(df_image_clean, df, test_size=0.2, random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6352eca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Samples: 1120\n",
      "Valid Samples: 281\n"
     ]
    }
   ],
   "source": [
    "print('Training Samples: {}\\nValid Samples: {}'.format(len(X_train), len(y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ecf1995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Validation set')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_bins=25\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "axes[0].hist(y_train, bins=num_bins, width=0.05)\n",
    "axes[0].set_title('Training set')\n",
    "axes[1].hist(y_valid, bins=num_bins, width=0.05)\n",
    "axes[1].set_title('Validation set')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab342b78",
   "metadata": {},
   "source": [
    "We begin the train part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818b79cc",
   "metadata": {},
   "source": [
    "## Train Image part ( 4 Dimensional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7eb7a282",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_image = np.array([df_to_numpy_image(X_train,i) for i in X_train.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b76b9e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1120, 270, 480, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_image.shape\n",
    "#(1120, 270, 480, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2b30723d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(101, 270, 480, 3)  We choose only the imagen part of the train data, \n",
    "#There are 1120 picturtes with resolutionn WIDTH = 480 and HEIGHT = 270 with 3 colors rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df9790fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We perform the reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc1d9da",
   "metadata": {},
   "source": [
    "numpy.reshape(a, newshape, order='C')\n",
    "\n",
    "- a - Array to be reshaped.\n",
    "- newshape  - The new shape should be compatible with the original shape.\n",
    "\n",
    "- order- Read the elements of a using this index order, and place the elements into the reshaped array using this index order.\n",
    "\n",
    "Gives a new shape to an array without changing its data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98b91110",
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH = 480\n",
    "HEIGHT = 270"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c508c1d",
   "metadata": {},
   "source": [
    "Using arr.reshape() will give a new shape to an array without changing the data. Just remember that when you use the reshape method, the array you want to produce needs to have the same number of elements as the original array."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10eb17a8",
   "metadata": {},
   "source": [
    "If you start with an array with N elements, you’ll need to make sure that your new array also has a total of N elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de82ec88",
   "metadata": {},
   "source": [
    "You can use reshape() to reshape your array. \n",
    "\n",
    "\n",
    "\n",
    "![title](np_reshape.png)\n",
    "\n",
    "With np.reshape, you can specify a few optional parameters:\n",
    "np.reshape(a, newshape=(d, e), order='C')\n",
    "\n",
    "a is the array to be reshaped.\n",
    "\n",
    "newshape is the new shape you want. You can specify an integer or a tuple of integers. If you specify an integer, the result will be an array of that length. The shape should be compatible with the original shape.\n",
    "\n",
    "order: C means to read/write the elements using C-like index order, F means to read/write the elements using Fortran-like index order, A means to read/write the elements in Fortran-like index order if a is Fortran contiguous in memory, C-like order otherwise. (This is an optional parameter and doesn’t need to be specified.)\n",
    "\n",
    "If you want to learn more about C and Fortran order, you can read more about the internal organization of NumPy arrays here. Essentially, C and Fortran orders have to do with how indices correspond to the order the array is stored in memory. In Fortran, when moving through the elements of a two-dimensional array as it is stored in memory, the first index is the most rapidly varying index. As the first index moves to the next row as it changes, the matrix is stored one column at a time. This is why Fortran is thought of as a Column-major language. In C on the other hand, the last index changes the most rapidly. The matrix is stored by rows, making it a Row-major language. What you do for C or Fortran depends on whether it’s more important to preserve the indexing convention or not reorder the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f50b801",
   "metadata": {},
   "source": [
    "We will reshape  270, 480 to  480, 270\n",
    "\n",
    "(101, 270, 480, 3) -> (101, 480, 270, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b6d1e6",
   "metadata": {},
   "source": [
    "What does -1 mean in numpy reshape? A numpy matrix can be reshaped into a vector using reshape function with parameter -1. The criterion to satisfy for providing the new shape is that 'The new shape should be compatible with the original shape'\n",
    "\n",
    "numpy allow us to give one of new shape parameter as -1 (eg: (-1,WIDTH,HEIGHT,3) . It simply means that it is an unknown dimension and we want numpy to figure it out. And numpy will figure this by looking at the 'length of the array and remaining dimensions' and making sure it satisfies the above mentioned criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e410f6bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1120, 480, 270, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For cleaned processed rgb\n",
    "X=X_image.reshape(-1,WIDTH,HEIGHT,3)\n",
    "X.shape\n",
    "#(101, 480, 270, 3) # the first number may change between the range (0 ,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9c451cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "435456000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05f6920",
   "metadata": {},
   "source": [
    "## Train Input part ( 1 Dimensional )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "68f72b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_numpy_input(df_input,index): \n",
    "    # flattening a 2d numpy array\n",
    "    # into 1d array\n",
    "    # and remove dtype at the end of numpy array\n",
    "    lista=df_input.loc[[index]].values.tolist()\n",
    "    arr=np.array(lista).ravel()\n",
    "    return arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab2ac7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = [df_to_numpy_input(y_train,i) for i in y_train.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f7f51ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b55535c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "61b6e004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1120"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f0d2f420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83302254",
   "metadata": {},
   "source": [
    "We begin the test part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32df747",
   "metadata": {},
   "source": [
    "## Test Image part ( 4 Dimensional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dfb28703",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = np.array([df_to_numpy_image(X_valid,i) for i in X_valid.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "90b6e32c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e022f16c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "628261f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(281, 270, 480, 3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image.shape\n",
    "#(26, 270, 480, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6509d5",
   "metadata": {},
   "source": [
    "numpy.reshape(a, newshape, order='C')\n",
    "\n",
    "- a - Array to be reshaped.\n",
    "- newshape  - The new shape should be compatible with the original shape.\n",
    "\n",
    "- order- Read the elements of a using this index order, and place the elements into the reshaped array using this index order.\n",
    "\n",
    "Gives a new shape to an array without changing its data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "132ae517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(281, 480, 270, 3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For processed\n",
    "test_x=test_image.reshape(-1,WIDTH,HEIGHT,3)\n",
    "test_x.shape\n",
    "#(26, 480, 270, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa78ed0",
   "metadata": {},
   "source": [
    "## Test Input part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ec8ee698",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = [df_to_numpy_input(y_valid,i) for i in y_valid.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1ba0a5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FILE_I_END = 1860\n",
    "FILE_I_END = 2\n",
    "WIDTH = 480\n",
    "HEIGHT = 270\n",
    "LR = 1e-3\n",
    "#EPOCHS = 30\n",
    "EPOCHS = 1\n",
    "MODEL_NAME = 'model_mmo0/test'\n",
    "PREV_MODEL = ''\n",
    "LOAD_MODEL = True\n",
    "\n",
    "wl = 0\n",
    "sl = 0\n",
    "al = 0\n",
    "dl = 0\n",
    "\n",
    "wal = 0\n",
    "wdl = 0\n",
    "sal = 0\n",
    "sdl = 0\n",
    "nkl = 0\n",
    "\n",
    "w = [1,0,0,0,0,0,0,0,0]\n",
    "s = [0,1,0,0,0,0,0,0,0]\n",
    "a = [0,0,1,0,0,0,0,0,0]\n",
    "d = [0,0,0,1,0,0,0,0,0]\n",
    "wa = [0,0,0,0,1,0,0,0,0]\n",
    "wd = [0,0,0,0,0,1,0,0,0]\n",
    "sa = [0,0,0,0,0,0,1,0,0]\n",
    "sd = [0,0,0,0,0,0,0,1,0]\n",
    "nk = [0,0,0,0,0,0,0,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "36bf9e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nk )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "32de1d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "size=[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f479433d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9684229f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda3\\envs\\pygta5\\lib\\site-packages\\tflearn\\initializations.py:110: calling UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\rusla\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\util\\deprecation.py:561: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
      "WARNING:tensorflow:From C:\\Users\\rusla\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\envs\\pygta5\\lib\\site-packages\\tflearn\\initializations.py:165: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model = googlenet(WIDTH, HEIGHT, 3, LR, output=29, model_name=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f9bc4ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 17  | total loss: \u001b[1m\u001b[32m1.53538\u001b[0m\u001b[0m | time: 51.795s\n",
      "| Momentum | epoch: 001 | loss: 1.53538 - acc: 0.5533 -- iter: 1088/1120\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32m1.95339\u001b[0m\u001b[0m | time: 62.214s\n",
      "| Momentum | epoch: 001 | loss: 1.95339 - acc: 0.5997 | val_loss: 1.54658 - val_acc: 1.0000 -- iter: 1120/1120\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "model.fit({'input': X}, \n",
    "          {'targets': Y}, \n",
    "          n_epoch=1, \n",
    "          validation_set=({'input': test_x},{'targets': test_y}), \n",
    "          snapshot_step=2500, \n",
    "          show_metric=True, \n",
    "          run_id=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5c1a0495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:C:\\Users\\rusla\\Dropbox\\23-GITHUB\\Projects\\BOT-MMORPG-WITH-AI\\versions\\0.01\\model_mmo1\\test is not in all_model_checkpoint_paths. Manually adding it.\n",
      "INFO:tensorflow:C:\\Users\\rusla\\Dropbox\\23-GITHUB\\Projects\\BOT-MMORPG-WITH-AI\\versions\\0.01\\model_mmo1\\test.data-00000-of-00001\n",
      "INFO:tensorflow:79900\n",
      "INFO:tensorflow:C:\\Users\\rusla\\Dropbox\\23-GITHUB\\Projects\\BOT-MMORPG-WITH-AI\\versions\\0.01\\model_mmo1\\test.index\n",
      "INFO:tensorflow:79900\n",
      "INFO:tensorflow:C:\\Users\\rusla\\Dropbox\\23-GITHUB\\Projects\\BOT-MMORPG-WITH-AI\\versions\\0.01\\model_mmo1\\test.meta\n",
      "INFO:tensorflow:80900\n"
     ]
    }
   ],
   "source": [
    "model.save(MODEL_NAME) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "dcac1755",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "def restartkernel() :\n",
    "    display_html(\"<script>Jupyter.notebook.kernel.restart()</script>\",raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2df67d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "restartkernel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfcb580",
   "metadata": {},
   "source": [
    "## Full code 1 - Draft simple big test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f198e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 17  | total loss: \u001b[1m\u001b[32m2.37240\u001b[0m\u001b[0m | time: 33.776s\n",
      "| Momentum | epoch: 001 | loss: 2.37240 - acc: 0.5488 -- iter: 1088/1120\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32m1.76822\u001b[0m\u001b[0m | time: 43.159s\n",
      "| Momentum | epoch: 001 | loss: 1.76822 - acc: 0.6130 | val_loss: 1.65745 - val_acc: 0.9680 -- iter: 1120/1120\n",
      "--\n",
      "SAVING MODEL!\n",
      "INFO:tensorflow:C:\\Users\\rusla\\Dropbox\\23-GITHUB\\Projects\\BOT-MMORPG-WITH-AI\\versions\\0.01\\model_mmo1\\test is not in all_model_checkpoint_paths. Manually adding it.\n",
      "INFO:tensorflow:C:\\Users\\rusla\\Dropbox\\23-GITHUB\\Projects\\BOT-MMORPG-WITH-AI\\versions\\0.01\\model_mmo1\\test.data-00000-of-00001\n",
      "INFO:tensorflow:79900\n",
      "INFO:tensorflow:C:\\Users\\rusla\\Dropbox\\23-GITHUB\\Projects\\BOT-MMORPG-WITH-AI\\versions\\0.01\\model_mmo1\\test.index\n",
      "INFO:tensorflow:79900\n",
      "INFO:tensorflow:C:\\Users\\rusla\\Dropbox\\23-GITHUB\\Projects\\BOT-MMORPG-WITH-AI\\versions\\0.01\\model_mmo1\\test.meta\n",
      "INFO:tensorflow:80900\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from grabscreen import grab_screen\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "from models import inception_v3 as googlenet\n",
    "from models import alexnet2\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#FILE_I_END = 30 # Multiple small files\n",
    "FILE_I_END = 1  # Single big file\n",
    "WIDTH = 480\n",
    "HEIGHT = 270\n",
    "LR = 1e-3\n",
    "EPOCHS = 1\n",
    "MODEL_NAME = 'model_mmo1/test'\n",
    "PREV_MODEL = ''\n",
    "LOAD_MODEL = False\n",
    "wl = 0\n",
    "sl = 0\n",
    "al = 0\n",
    "dl = 0\n",
    "wal = 0\n",
    "wdl = 0\n",
    "sal = 0\n",
    "sdl = 0\n",
    "nkl = 0\n",
    "w = [1,0,0,0,0,0,0,0,0]\n",
    "s = [0,1,0,0,0,0,0,0,0]\n",
    "a = [0,0,1,0,0,0,0,0,0]\n",
    "d = [0,0,0,1,0,0,0,0,0]\n",
    "wa = [0,0,0,0,1,0,0,0,0]\n",
    "wd = [0,0,0,0,0,1,0,0,0]\n",
    "sa = [0,0,0,0,0,0,1,0,0]\n",
    "sd = [0,0,0,0,0,0,0,1,0]\n",
    "nk = [0,0,0,0,0,0,0,0,1]\n",
    "model = googlenet(WIDTH, HEIGHT, 3, LR, output=29, model_name=MODEL_NAME)\n",
    "\n",
    "def df_to_numpy_input(df_input,index): \n",
    "    # flattening a 2d numpy array\n",
    "    # into 1d array\n",
    "    # and remove dtype at the end of numpy array\n",
    "    lista=df_input.loc[[index]].values.tolist()\n",
    "    arr=np.array(lista).ravel()\n",
    "    return arr\n",
    "\n",
    "def df_to_numpy_image(df_image_clean,index):\n",
    "    #select the row with index label 'index'\n",
    "    image_clean=df_image_clean.loc[[index]].T.to_numpy()\n",
    "    lists =image_clean.tolist()\n",
    "    # Nested List Comprehension to flatten a given 2-D matrix\n",
    "    # 2-D List\n",
    "    matrix = lists\n",
    "    flatten_matrix = [val.tolist() for sublist in matrix for val in sublist]\n",
    "    # converting list to array\n",
    "    arr = np.array(flatten_matrix)\n",
    "    return arr\n",
    "def cleaning_data(train_data , show=False):\n",
    "    #Creation and cleaning of the input dataframe\n",
    "    df = pd.DataFrame()\n",
    "    for i in range(len(train_data)):\n",
    "        row=list(train_data[i][1])\n",
    "        #print(row)\n",
    "        temp = pd.DataFrame([row])\n",
    "       # print(temp)\n",
    "        df = pd.concat([df, temp])\n",
    "    df=df.reset_index(drop=True)\n",
    "\n",
    "    # Parameters of the cleaning part\n",
    "    num_bins = 25\n",
    "    # We choose the threshold by choosing the RX diffeerent of zero\n",
    "    threshold= (df[13] != 0).astype(int).sum(axis=0)\n",
    "    samples_per_bin = threshold\n",
    "    hist, bins = np.histogram(df[13], num_bins)\n",
    "    center = (bins[:-1]+ bins[1:]) * 0.5\n",
    "    \n",
    "    #Cleaning procedure\n",
    "    remove_list = []\n",
    "    for j in range(num_bins):\n",
    "        list_ = []\n",
    "        for i in range(len(df[13])):\n",
    "            serie=df[13].iloc[[i]]\n",
    "            ls = serie.tolist()\n",
    "            if ls[0] >= bins[j] and ls[0] <= bins[j+1]:\n",
    "                list_.append(i)      \n",
    "        #list_ = shuffle(list_)\n",
    "        list_ = list_[samples_per_bin:]\n",
    "        remove_list.extend(list_)\n",
    "        \n",
    "    #Implementation of the cleaning    \n",
    "    df_removed=df.drop(remove_list, axis=0, inplace=False)\n",
    "    df.drop(df.index[remove_list], inplace=True)\n",
    "    print('remaining:', len(df))\n",
    "    df=df.reset_index(drop=True) # We reset the index ! attention    \n",
    "    if show == True:\n",
    "        #Visualization of cleaning\n",
    "        hist, _ = np.histogram(df[13], (num_bins))\n",
    "        plt.bar(center, hist, width=0.05)\n",
    "        plt.plot((np.min(df[13]), np.max(df[13])), (samples_per_bin, samples_per_bin))\n",
    "    \n",
    "    #Creation and cleaning of the image dataframe\n",
    "    \n",
    "    df_image = pd.DataFrame()\n",
    "    for i in range(len(train_data)):\n",
    "        row=list(train_data[i][0]) # For images  Here we lost the (i, 480, 3) shape\n",
    "        #print(row)    \n",
    "        temp = pd.DataFrame([row])\n",
    "       # print(temp)\n",
    "        df_image = pd.concat([df_image, temp])\n",
    "    df_image=df_image.reset_index(drop=True)\n",
    "    df_image_removed=df_image.drop(remove_list, axis=0, inplace=False)\n",
    "    df_image_clean=df_image_removed.reset_index(drop=True)\n",
    "    #We verify that the dimensions are the same\n",
    "    assert len(df) == len(df_image_clean), \"The dimensions are not equal, something is wrong \"\n",
    "    \n",
    "    return df_image_clean, df\n",
    "if LOAD_MODEL:\n",
    "    model.load(PREV_MODEL)\n",
    "    print('We have loaded a previous model!!!!')\n",
    "# iterates through the training files\n",
    "for e in range(EPOCHS):\n",
    "    data_order = [i for i in range(1,FILE_I_END+1)]\n",
    "    shuffle(data_order)\n",
    "    for count,i in enumerate(data_order):\n",
    "        try:\n",
    "\n",
    "            # loading cleaned big files           \n",
    "            df_image_clean=pd.read_pickle('clean/data/x_training_data.csv')  \n",
    "            df=pd.read_csv('clean/data/y_training_data.csv')  \n",
    "            #We verify that the dimensions are the same\n",
    "            assert len(df) == len(df_image_clean), \"The dimensions are not equal, something is wrong \"\n",
    "            \n",
    "            X_train, X_valid, y_train, y_valid = train_test_split(df_image_clean, df, test_size=0.2, random_state=6)\n",
    "            # Train Image part ( 4 Dimensional)\n",
    "            X_image = np.array([df_to_numpy_image(X_train,i) for i in X_train.index])\n",
    "            X=X_image.reshape(-1,WIDTH,HEIGHT,3)\n",
    "            #Train Input part ( 1 Dimensional )\n",
    "            Y = [df_to_numpy_input(y_train,i) for i in y_train.index]\n",
    "            # Test Image part ( 4 Dimensional)\n",
    "            test_image = np.array([df_to_numpy_image(X_valid,i) for i in X_valid.index])\n",
    "            test_x=test_image.reshape(-1,WIDTH,HEIGHT,3)\n",
    "            ## Test Input part( 1 Dimensional )\n",
    "            test_y = [df_to_numpy_input(y_valid,i) for i in y_valid.index]\n",
    " \n",
    "            model.fit({'input': X}, \n",
    "                      {'targets': Y}, \n",
    "                      n_epoch=1, \n",
    "                      validation_set=({'input': test_x},{'targets': test_y}), \n",
    "                      snapshot_step=2500, \n",
    "                      show_metric=True, \n",
    "                      run_id=MODEL_NAME)\n",
    "            if count%10 == 0:\n",
    "                print('SAVING MODEL!')\n",
    "                model.save(MODEL_NAME)                  \n",
    "        except Exception as e:\n",
    "            print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3059ed8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "restartkernel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efd2aa5",
   "metadata": {},
   "source": [
    "## Full code 2 multiple files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "963df29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 153  | total loss: \u001b[1m\u001b[32m1.22031\u001b[0m\u001b[0m | time: 2.202s\n",
      "| Momentum | epoch: 139 | loss: 1.22031 - acc: 0.6207 -- iter: 64/81\n",
      "Training Step: 154  | total loss: \u001b[1m\u001b[32m1.34489\u001b[0m\u001b[0m | time: 3.622s\n",
      "| Momentum | epoch: 139 | loss: 1.34489 - acc: 0.6149 | val_loss: 1.24442 - val_acc: 0.8095 -- iter: 81/81\n",
      "--\n",
      "---------------------------------\n",
      "Run id: model_mmo2a/test\n",
      "Log directory: log/\n",
      "---------------------------------\n",
      "Training samples: 30\n",
      "Validation samples: 8\n",
      "--\n",
      "Training Step: 155  | total loss: \u001b[1m\u001b[32m1.55729\u001b[0m\u001b[0m | time: 2.655s\n",
      "| Momentum | epoch: 140 | loss: 1.55729 - acc: 0.5945 | val_loss: -0.21464 - val_acc: 0.2500 -- iter: 30/30\n",
      "--\n",
      "---------------------------------\n",
      "Run id: model_mmo2a/test\n",
      "Log directory: log/\n",
      "---------------------------------\n",
      "Training samples: 14\n",
      "Validation samples: 4\n",
      "--\n",
      "Training Step: 156  | total loss: \u001b[1m\u001b[32m1.82079\u001b[0m\u001b[0m | time: 2.240s\n",
      "| Momentum | epoch: 141 | loss: 1.82079 - acc: 0.5951 | val_loss: -5.63777 - val_acc: 0.0000 -- iter: 14/14\n",
      "--\n",
      "SAVING MODEL!\n",
      "INFO:tensorflow:C:\\Users\\rusla\\Dropbox\\23-GITHUB\\Projects\\BOT-MMORPG-WITH-AI\\versions\\0.01\\model_mmo2a\\test is not in all_model_checkpoint_paths. Manually adding it.\n",
      "INFO:tensorflow:C:\\Users\\rusla\\Dropbox\\23-GITHUB\\Projects\\BOT-MMORPG-WITH-AI\\versions\\0.01\\model_mmo2a\\test.data-00000-of-00001\n",
      "INFO:tensorflow:79900\n",
      "INFO:tensorflow:C:\\Users\\rusla\\Dropbox\\23-GITHUB\\Projects\\BOT-MMORPG-WITH-AI\\versions\\0.01\\model_mmo2a\\test.index\n",
      "INFO:tensorflow:79900\n",
      "INFO:tensorflow:C:\\Users\\rusla\\Dropbox\\23-GITHUB\\Projects\\BOT-MMORPG-WITH-AI\\versions\\0.01\\model_mmo2a\\test.meta\n",
      "INFO:tensorflow:81000\n",
      "---------------------------------\n",
      "Run id: model_mmo2a/test\n",
      "Log directory: log/\n",
      "---------------------------------\n",
      "Training samples: 62\n",
      "Validation samples: 16\n",
      "--\n",
      "Training Step: 157  | total loss: \u001b[1m\u001b[32m1.52619\u001b[0m\u001b[0m | time: 3.409s\n",
      "| Momentum | epoch: 142 | loss: 1.52619 - acc: 0.5927 | val_loss: 2.20062 - val_acc: 0.0000 -- iter: 62/62\n",
      "--\n",
      "---------------------------------\n",
      "Run id: model_mmo2a/test\n",
      "Log directory: log/\n",
      "---------------------------------\n",
      "Training samples: 41\n",
      "Validation samples: 11\n",
      "--\n",
      "Training Step: 158  | total loss: \u001b[1m\u001b[32m1.90375\u001b[0m\u001b[0m | time: 2.886s\n",
      "| Momentum | epoch: 143 | loss: 1.90375 - acc: 0.5818 | val_loss: 7.63942 - val_acc: 0.3636 -- iter: 41/41\n",
      "--\n",
      "---------------------------------\n",
      "Run id: model_mmo2a/test\n",
      "Log directory: log/\n",
      "---------------------------------\n",
      "Training samples: 9\n",
      "Validation samples: 3\n",
      "--\n",
      "Training Step: 159  | total loss: \u001b[1m\u001b[32m2.16218\u001b[0m\u001b[0m | time: 2.098s\n",
      "| Momentum | epoch: 144 | loss: 2.16218 - acc: 0.5651 | val_loss: 1.39048 - val_acc: 1.0000 -- iter: 9/9\n",
      "--\n",
      "---------------------------------\n",
      "Run id: model_mmo2a/test\n",
      "Log directory: log/\n",
      "---------------------------------\n",
      "Training samples: 19\n",
      "Validation samples: 5\n",
      "--\n",
      "Training Step: 160  | total loss: \u001b[1m\u001b[32m2.12818\u001b[0m\u001b[0m | time: 2.417s\n",
      "| Momentum | epoch: 145 | loss: 2.12818 - acc: 0.5308 | val_loss: 3.37469 - val_acc: 1.0000 -- iter: 19/19\n",
      "--\n",
      "---------------------------------\n",
      "Run id: model_mmo2a/test\n",
      "Log directory: log/\n",
      "---------------------------------\n",
      "Training samples: 40\n",
      "Validation samples: 10\n",
      "--\n",
      "Training Step: 161  | total loss: \u001b[1m\u001b[32m2.23183\u001b[0m\u001b[0m | time: 2.816s\n",
      "| Momentum | epoch: 146 | loss: 2.23183 - acc: 0.5251 | val_loss: 2.80137 - val_acc: 1.0000 -- iter: 40/40\n",
      "--\n",
      "---------------------------------\n",
      "Run id: model_mmo2a/test\n",
      "Log directory: log/\n",
      "---------------------------------\n",
      "Training samples: 30\n",
      "Validation samples: 8\n",
      "--\n",
      "Training Step: 162  | total loss: \u001b[1m\u001b[32m2.26401\u001b[0m\u001b[0m | time: 2.595s\n",
      "| Momentum | epoch: 147 | loss: 2.26401 - acc: 0.5501 | val_loss: 2.58221 - val_acc: 1.0000 -- iter: 30/30\n",
      "--\n",
      "---------------------------------\n",
      "Run id: model_mmo2a/test\n",
      "Log directory: log/\n",
      "---------------------------------\n",
      "Training samples: 16\n",
      "Validation samples: 4\n",
      "--\n",
      "Training Step: 163  | total loss: \u001b[1m\u001b[32m2.14459\u001b[0m\u001b[0m | time: 2.291s\n",
      "| Momentum | epoch: 148 | loss: 2.14459 - acc: 0.5784 | val_loss: -0.70110 - val_acc: 1.0000 -- iter: 16/16\n",
      "--\n",
      "---------------------------------\n",
      "Run id: model_mmo2a/test\n",
      "Log directory: log/\n",
      "---------------------------------\n",
      "Training samples: 9\n",
      "Validation samples: 3\n",
      "--\n",
      "Training Step: 164  | total loss: \u001b[1m\u001b[32m1.82445\u001b[0m\u001b[0m | time: 2.129s\n",
      "| Momentum | epoch: 149 | loss: 1.82445 - acc: 0.5893 | val_loss: 6.46450 - val_acc: 1.0000 -- iter: 9/9\n",
      "--\n",
      "---------------------------------\n",
      "Run id: model_mmo2a/test\n",
      "Log directory: log/\n",
      "---------------------------------\n",
      "Training samples: 32\n",
      "Validation samples: 8\n",
      "--\n",
      "Training Step: 165  | total loss: \u001b[1m\u001b[32m1.96339\u001b[0m\u001b[0m | time: 2.680s\n",
      "| Momentum | epoch: 150 | loss: 1.96339 - acc: 0.5860 | val_loss: -1.73103 - val_acc: 1.0000 -- iter: 32/32\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from grabscreen import grab_screen\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "from models import inception_v3 as googlenet\n",
    "from models import alexnet2\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Clean files\n",
    "clean_label =  False\n",
    "\n",
    "FILE_I_END = 30 # Multiple small files\n",
    "WIDTH = 480\n",
    "HEIGHT = 270\n",
    "LR = 1e-3\n",
    "EPOCHS = 5\n",
    "#EPOCHS = 1\n",
    "MODEL_NAME = 'model_mmo2a/test'\n",
    "PREV_MODEL = ''\n",
    "LOAD_MODEL = False\n",
    "wl = 0\n",
    "sl = 0\n",
    "al = 0\n",
    "dl = 0\n",
    "wal = 0\n",
    "wdl = 0\n",
    "sal = 0\n",
    "sdl = 0\n",
    "nkl = 0\n",
    "w = [1,0,0,0,0,0,0,0,0]\n",
    "s = [0,1,0,0,0,0,0,0,0]\n",
    "a = [0,0,1,0,0,0,0,0,0]\n",
    "d = [0,0,0,1,0,0,0,0,0]\n",
    "wa = [0,0,0,0,1,0,0,0,0]\n",
    "wd = [0,0,0,0,0,1,0,0,0]\n",
    "sa = [0,0,0,0,0,0,1,0,0]\n",
    "sd = [0,0,0,0,0,0,0,1,0]\n",
    "nk = [0,0,0,0,0,0,0,0,1]\n",
    "model = googlenet(WIDTH, HEIGHT, 3, LR, output=29, model_name=MODEL_NAME)\n",
    "\n",
    "def df_to_numpy_input(df_input,index): \n",
    "    # flattening a 2d numpy array\n",
    "    # into 1d array\n",
    "    # and remove dtype at the end of numpy array\n",
    "    lista=df_input.loc[[index]].values.tolist()\n",
    "    arr=np.array(lista).ravel()\n",
    "    return arr\n",
    "\n",
    "def df_to_numpy_image(df_image_clean,index):\n",
    "    #select the row with index label 'index'\n",
    "    image_clean=df_image_clean.loc[[index]].T.to_numpy()\n",
    "    lists =image_clean.tolist()\n",
    "    # Nested List Comprehension to flatten a given 2-D matrix\n",
    "    # 2-D List\n",
    "    matrix = lists\n",
    "    flatten_matrix = [val.tolist() for sublist in matrix for val in sublist]\n",
    "    # converting list to array\n",
    "    arr = np.array(flatten_matrix)\n",
    "    return arr\n",
    "def cleaning_data(train_data , show=False):\n",
    "    #Creation and cleaning of the input dataframe\n",
    "    df = pd.DataFrame()\n",
    "    for i in range(len(train_data)):\n",
    "        row=list(train_data[i][1])\n",
    "        #print(row)\n",
    "        temp = pd.DataFrame([row])\n",
    "       # print(temp)\n",
    "        df = pd.concat([df, temp])\n",
    "    df=df.reset_index(drop=True)\n",
    "\n",
    "    # Parameters of the cleaning part\n",
    "    num_bins = 25\n",
    "    # We choose the threshold by choosing the RX diffeerent of zero\n",
    "    threshold= (df[13] != 0).astype(int).sum(axis=0)\n",
    "    samples_per_bin = threshold\n",
    "    hist, bins = np.histogram(df[13], num_bins)\n",
    "    center = (bins[:-1]+ bins[1:]) * 0.5\n",
    "    \n",
    "    #Cleaning procedure\n",
    "    remove_list = []\n",
    "    for j in range(num_bins):\n",
    "        list_ = []\n",
    "        for i in range(len(df[13])):\n",
    "            serie=df[13].iloc[[i]]\n",
    "            ls = serie.tolist()\n",
    "            if ls[0] >= bins[j] and ls[0] <= bins[j+1]:\n",
    "                list_.append(i)      \n",
    "        #list_ = shuffle(list_)\n",
    "        list_ = list_[samples_per_bin:]\n",
    "        remove_list.extend(list_)\n",
    "        \n",
    "    #Implementation of the cleaning    \n",
    "    df_removed=df.drop(remove_list, axis=0, inplace=False)\n",
    "    df.drop(df.index[remove_list], inplace=True)\n",
    "    print('remaining:', len(df))\n",
    "    df=df.reset_index(drop=True) # We reset the index ! attention    \n",
    "    if show == True:\n",
    "        #Visualization of cleaning\n",
    "        hist, _ = np.histogram(df[13], (num_bins))\n",
    "        plt.bar(center, hist, width=0.05)\n",
    "        plt.plot((np.min(df[13]), np.max(df[13])), (samples_per_bin, samples_per_bin))\n",
    "    \n",
    "    #Creation and cleaning of the image dataframe\n",
    "    \n",
    "    df_image = pd.DataFrame()\n",
    "    for i in range(len(train_data)):\n",
    "        row=list(train_data[i][0]) # For images  Here we lost the (i, 480, 3) shape\n",
    "        #print(row)    \n",
    "        temp = pd.DataFrame([row])\n",
    "       # print(temp)\n",
    "        df_image = pd.concat([df_image, temp])\n",
    "    df_image=df_image.reset_index(drop=True)\n",
    "    df_image_removed=df_image.drop(remove_list, axis=0, inplace=False)\n",
    "    df_image_clean=df_image_removed.reset_index(drop=True)\n",
    "    #We verify that the dimensions are the same\n",
    "    assert len(df) == len(df_image_clean), \"The dimensions are not equal, something is wrong \"\n",
    "    \n",
    "    return df_image_clean, df\n",
    "if LOAD_MODEL:\n",
    "    model.load(PREV_MODEL)\n",
    "    print('We have loaded a previous model!!!!')\n",
    "# iterates through the training files\n",
    "for e in range(EPOCHS):\n",
    "    data_order = [i for i in range(1,FILE_I_END+1)]\n",
    "    shuffle(data_order)\n",
    "    for count,i in enumerate(data_order):\n",
    "        try:\n",
    "            x_file_name = 'clean/x_training_data-{}.csv'.format(i)\n",
    "            y_file_name = 'clean/y_training_data-{}.csv'.format(i)  \n",
    "            \n",
    "            if clean_label ==  True :\n",
    "                    file_name = 'preprocessed_training_data-{}.npy'.format(i)\n",
    "                    print(file_name)\n",
    "                    # full file information\n",
    "                    train_data = np.load(file_name,allow_pickle=True)\n",
    "                    df_image_clean, df = cleaning_data(train_data,show=False)\n",
    "                    df_image_clean.to_pickle(x_file_name)\n",
    "                    df.to_csv(y_file_name,index=False)\n",
    "\n",
    "            # loading cleaned small files           \n",
    "            df_image_clean=pd.read_pickle(x_file_name)  \n",
    "            df=pd.read_csv(y_file_name)  \n",
    "            #We verify that the dimensions are the same\n",
    "            assert len(df) == len(df_image_clean), \"The dimensions are not equal, something is wrong \"\n",
    "            \n",
    "            X_train, X_valid, y_train, y_valid = train_test_split(df_image_clean, df, test_size=0.2, random_state=6)\n",
    "            # Train Image part ( 4 Dimensional)\n",
    "            X_image = np.array([df_to_numpy_image(X_train,i) for i in X_train.index])\n",
    "            X=X_image.reshape(-1,WIDTH,HEIGHT,3)\n",
    "            #Train Input part ( 1 Dimensional )\n",
    "            Y = [df_to_numpy_input(y_train,i) for i in y_train.index]\n",
    "            # Test Image part ( 4 Dimensional)\n",
    "            test_image = np.array([df_to_numpy_image(X_valid,i) for i in X_valid.index])\n",
    "            test_x=test_image.reshape(-1,WIDTH,HEIGHT,3)\n",
    "            ## Test Input part( 1 Dimensional )\n",
    "            test_y = [df_to_numpy_input(y_valid,i) for i in y_valid.index]\n",
    " \n",
    "            model.fit({'input': X}, \n",
    "                      {'targets': Y}, \n",
    "                      n_epoch=1, \n",
    "                      validation_set=({'input': test_x},{'targets': test_y}), \n",
    "                      snapshot_step=2500, \n",
    "                      show_metric=True, \n",
    "                      run_id=MODEL_NAME)\n",
    "            if count%10 == 0:\n",
    "                print('SAVING MODEL!')\n",
    "                model.save(MODEL_NAME)                  \n",
    "        except Exception as e:\n",
    "            print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04931a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "restartkernel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3cc8bb",
   "metadata": {},
   "source": [
    "## Full code 3 - Single big file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26e4c57e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 539  | total loss: \u001b[1m\u001b[32m1.29352\u001b[0m\u001b[0m | time: 22.141s\n",
      "| Momentum | epoch: 030 | loss: 1.29352 - acc: 0.6372 -- iter: 1088/1120\n",
      "Training Step: 540  | total loss: \u001b[1m\u001b[32m1.42561\u001b[0m\u001b[0m | time: 25.584s\n",
      "| Momentum | epoch: 030 | loss: 1.42561 - acc: 0.6328 | val_loss: 1.20256 - val_acc: 0.9288 -- iter: 1120/1120\n",
      "--\n",
      "SAVING MODEL!\n",
      "INFO:tensorflow:C:\\Users\\rusla\\Dropbox\\23-GITHUB\\Projects\\BOT-MMORPG-WITH-AI\\versions\\0.01\\model_mmo3\\test is not in all_model_checkpoint_paths. Manually adding it.\n",
      "INFO:tensorflow:C:\\Users\\rusla\\Dropbox\\23-GITHUB\\Projects\\BOT-MMORPG-WITH-AI\\versions\\0.01\\model_mmo3\\test.data-00000-of-00001\n",
      "INFO:tensorflow:79900\n",
      "INFO:tensorflow:C:\\Users\\rusla\\Dropbox\\23-GITHUB\\Projects\\BOT-MMORPG-WITH-AI\\versions\\0.01\\model_mmo3\\test.index\n",
      "INFO:tensorflow:79900\n",
      "INFO:tensorflow:C:\\Users\\rusla\\Dropbox\\23-GITHUB\\Projects\\BOT-MMORPG-WITH-AI\\versions\\0.01\\model_mmo3\\test.meta\n",
      "INFO:tensorflow:80900\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from grabscreen import grab_screen\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "from models import inception_v3 as googlenet\n",
    "from models import alexnet2\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Single big file\n",
    "WIDTH = 480\n",
    "HEIGHT = 270\n",
    "LR = 1e-3\n",
    "EPOCHS = 30\n",
    "\n",
    "MODEL_NAME = 'model_mmo3/test'\n",
    "PREV_MODEL = ''\n",
    "LOAD_MODEL = False\n",
    "wl = 0\n",
    "sl = 0\n",
    "al = 0\n",
    "dl = 0\n",
    "wal = 0\n",
    "wdl = 0\n",
    "sal = 0\n",
    "sdl = 0\n",
    "nkl = 0\n",
    "w = [1,0,0,0,0,0,0,0,0]\n",
    "s = [0,1,0,0,0,0,0,0,0]\n",
    "a = [0,0,1,0,0,0,0,0,0]\n",
    "d = [0,0,0,1,0,0,0,0,0]\n",
    "wa = [0,0,0,0,1,0,0,0,0]\n",
    "wd = [0,0,0,0,0,1,0,0,0]\n",
    "sa = [0,0,0,0,0,0,1,0,0]\n",
    "sd = [0,0,0,0,0,0,0,1,0]\n",
    "nk = [0,0,0,0,0,0,0,0,1]\n",
    "model = googlenet(WIDTH, HEIGHT, 3, LR, output=29, model_name=MODEL_NAME)\n",
    "\n",
    "def df_to_numpy_input(df_input,index): \n",
    "    # flattening a 2d numpy array\n",
    "    # into 1d array\n",
    "    # and remove dtype at the end of numpy array\n",
    "    lista=df_input.loc[[index]].values.tolist()\n",
    "    arr=np.array(lista).ravel()\n",
    "    return arr\n",
    "\n",
    "def df_to_numpy_image(df_image_clean,index):\n",
    "    #select the row with index label 'index'\n",
    "    image_clean=df_image_clean.loc[[index]].T.to_numpy()\n",
    "    lists =image_clean.tolist()\n",
    "    # Nested List Comprehension to flatten a given 2-D matrix\n",
    "    # 2-D List\n",
    "    matrix = lists\n",
    "    flatten_matrix = [val.tolist() for sublist in matrix for val in sublist]\n",
    "    # converting list to array\n",
    "    arr = np.array(flatten_matrix)\n",
    "    return arr\n",
    "\n",
    "if LOAD_MODEL:\n",
    "    model.load(PREV_MODEL)\n",
    "    print('We have loaded a previous model!!!!')\n",
    "    \n",
    "# loading cleaned big files           \n",
    "df_image_clean=pd.read_pickle('clean/data/x_training_data.csv')  \n",
    "df=pd.read_csv('clean/data/y_training_data.csv')  \n",
    "#We verify that the dimensions are the same\n",
    "assert len(df) == len(df_image_clean), \"The dimensions are not equal, something is wrong \"\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(df_image_clean, df, test_size=0.2, random_state=6)\n",
    "# Train Image part ( 4 Dimensional)\n",
    "X_image = np.array([df_to_numpy_image(X_train,i) for i in X_train.index])\n",
    "X=X_image.reshape(-1,WIDTH,HEIGHT,3)\n",
    "#Train Input part ( 1 Dimensional )\n",
    "Y = [df_to_numpy_input(y_train,i) for i in y_train.index]\n",
    "# Test Image part ( 4 Dimensional)\n",
    "test_image = np.array([df_to_numpy_image(X_valid,i) for i in X_valid.index])\n",
    "test_x=test_image.reshape(-1,WIDTH,HEIGHT,3)\n",
    "## Test Input part( 1 Dimensional )\n",
    "test_y = [df_to_numpy_input(y_valid,i) for i in y_valid.index]        \n",
    "try:\n",
    "    model.fit({'input': X}, \n",
    "              {'targets': Y}, \n",
    "              n_epoch=EPOCHS, \n",
    "              validation_set=({'input': test_x},{'targets': test_y}), \n",
    "              snapshot_step=2500, \n",
    "              show_metric=True, \n",
    "              run_id=MODEL_NAME)\n",
    "    print('SAVING MODEL!')\n",
    "    model.save(MODEL_NAME)                  \n",
    "except Exception as e:\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc596921",
   "metadata": {},
   "source": [
    "## Full code 4 - Single big file with oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053eb645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 83  | total loss: \u001b[1m\u001b[32m1.65821\u001b[0m\u001b[0m | time: 15.287s\n",
      "\u001b[2K\r",
      "| Momentum | epoch: 006 | loss: 1.65821 - acc: 0.6116 -- iter: 832/858\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from grabscreen import grab_screen\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "from models import inception_v3 as googlenet\n",
    "from models import alexnet2\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Single big file\n",
    "WIDTH = 480\n",
    "HEIGHT = 270\n",
    "LR = 1e-3\n",
    "EPOCHS = 30\n",
    "\n",
    "MODEL_NAME = 'model_mmo4/test'\n",
    "PREV_MODEL = ''\n",
    "LOAD_MODEL = False\n",
    "wl = 0\n",
    "sl = 0\n",
    "al = 0\n",
    "dl = 0\n",
    "wal = 0\n",
    "wdl = 0\n",
    "sal = 0\n",
    "sdl = 0\n",
    "nkl = 0\n",
    "w = [1,0,0,0,0,0,0,0,0]\n",
    "s = [0,1,0,0,0,0,0,0,0]\n",
    "a = [0,0,1,0,0,0,0,0,0]\n",
    "d = [0,0,0,1,0,0,0,0,0]\n",
    "wa = [0,0,0,0,1,0,0,0,0]\n",
    "wd = [0,0,0,0,0,1,0,0,0]\n",
    "sa = [0,0,0,0,0,0,1,0,0]\n",
    "sd = [0,0,0,0,0,0,0,1,0]\n",
    "nk = [0,0,0,0,0,0,0,0,1]\n",
    "model = googlenet(WIDTH, HEIGHT, 3, LR, output=29, model_name=MODEL_NAME)\n",
    "\n",
    "def df_to_numpy_input(df_input,index): \n",
    "    # flattening a 2d numpy array\n",
    "    # into 1d array\n",
    "    # and remove dtype at the end of numpy array\n",
    "    lista=df_input.loc[[index]].values.tolist()\n",
    "    arr=np.array(lista).ravel()\n",
    "    return arr\n",
    "\n",
    "def df_to_numpy_image(df_image_clean,index):\n",
    "    #select the row with index label 'index'\n",
    "    image_clean=df_image_clean.loc[[index]].T.to_numpy()\n",
    "    lists =image_clean.tolist()\n",
    "    # Nested List Comprehension to flatten a given 2-D matrix\n",
    "    # 2-D List\n",
    "    matrix = lists\n",
    "    flatten_matrix = [val.tolist() for sublist in matrix for val in sublist]\n",
    "    # converting list to array\n",
    "    arr = np.array(flatten_matrix)\n",
    "    return arr\n",
    "\n",
    "if LOAD_MODEL:\n",
    "    model.load(PREV_MODEL)\n",
    "    print('We have loaded a previous model!!!!')\n",
    "    \n",
    "# loading cleaned big files   with undersampling        \n",
    "df_image_clean=pd.read_pickle('clean/data/undersampling/x_training_data.csv')  \n",
    "df=pd.read_csv('clean/data/undersampling/y_training_data.csv')  \n",
    "#We verify that the dimensions are the same\n",
    "assert len(df) == len(df_image_clean), \"The dimensions are not equal, something is wrong \"\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(df_image_clean, df, test_size=0.2, random_state=6)\n",
    "# Train Image part ( 4 Dimensional)\n",
    "X_image = np.array([df_to_numpy_image(X_train,i) for i in X_train.index])\n",
    "X=X_image.reshape(-1,WIDTH,HEIGHT,3)\n",
    "#Train Input part ( 1 Dimensional )\n",
    "Y = [df_to_numpy_input(y_train,i) for i in y_train.index]\n",
    "# Test Image part ( 4 Dimensional)\n",
    "test_image = np.array([df_to_numpy_image(X_valid,i) for i in X_valid.index])\n",
    "test_x=test_image.reshape(-1,WIDTH,HEIGHT,3)\n",
    "## Test Input part( 1 Dimensional )\n",
    "test_y = [df_to_numpy_input(y_valid,i) for i in y_valid.index]        \n",
    "try:\n",
    "    model.fit({'input': X}, \n",
    "              {'targets': Y}, \n",
    "              n_epoch=EPOCHS, \n",
    "              validation_set=({'input': test_x},{'targets': test_y}), \n",
    "              snapshot_step=2500, \n",
    "              show_metric=True, \n",
    "              run_id=MODEL_NAME)\n",
    "    print('SAVING MODEL!')\n",
    "    model.save(MODEL_NAME)                  \n",
    "except Exception as e:\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2b77bd",
   "metadata": {},
   "source": [
    "## TensorBoard in Terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2617a334",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b35ad70",
   "metadata": {},
   "source": [
    "After the learning step has completed, you can just open a terminal and enter the command below\n",
    "$ tensorboard --logdir='/tmp/tflearn_logs'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c9dbfc",
   "metadata": {},
   "source": [
    "tensorboard --logdir='/log/model_clean/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75bba92",
   "metadata": {},
   "source": [
    "I have to be sure that model = tflearn.DNN(network, checkpoint_path='/tmp/tflearn_logs/',max_checkpoints=1, tensorboard_verbose=0) By adjusting tensorboard_variable, we tell  Tflearn to save metrics that Tensorboard will master later.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f9fc46",
   "metadata": {},
   "source": [
    "## TensorBoard in Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bbe9d1",
   "metadata": {},
   "source": [
    "TensorBoard is a great tool providing visualization of many metrics necessary to evaluate TensorFlow model training. It used to be difficult to bring up this tool especially in a hosted Jupyter Notebook environment such as Google Colab, Kaggle notebook and Coursera's Notebook etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af7d0c8",
   "metadata": {},
   "source": [
    "Start by installing TF 2.0 and loading the TensorBoard notebook extension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1592a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q tf-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac758b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datetime, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cadebbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c463fc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip uninstall tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d674f8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tf-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf2b2131",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip uninstall tf-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48f6a30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --force-reinstall tf-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32e44bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c83f6f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-2ed538613c388a52\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-2ed538613c388a52\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6221d47",
   "metadata": {},
   "source": [
    "The same TensorBoard backend is reused by issuing the same command. If a different logs directory was chosen, a new instance of TensorBoard would be opened. Ports are managed automatically.\n",
    "\n",
    "Any new interesting feature worth mentioning is the \"conceptual graph\". To see the conceptual graph, select the “keras” tag. For this example, you’ll see a collapsed Sequential node. Double-click the node to see the model’s structure:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b9f7b4",
   "metadata": {},
   "source": [
    "## Alternative Approaches\n",
    "In this notebook we have used InceptionV3, however it is possible use differnet available  popular neural networks.\n",
    "Taking into account Keras, In deep learning models there are some applications available alongside pre-trained weights. These models can be used for prediction, feature extraction, and fine-tuning.\n",
    "\n",
    "Weights are downloaded automatically when instantiating a model. They are stored at ~/.keras/models/.\n",
    "\n",
    "Upon instantiation, the models will be built according to the image data format set in your Keras configuration file at ~/.keras/keras.json. For instance, if you have set image_data_format=channels_last, then any model loaded from this repository will get built according to the TensorFlow data format convention, \"Height-Width-Depth\".\n",
    "\n",
    "Available models\n",
    "Model\tSize (MB)\tTop-1 Accuracy\tTop-5 Accuracy\tParameters\tDepth\tTime (ms) per inference step (CPU)\tTime (ms) per inference step (GPU)\n",
    "- Xception\t88\t79.0%\t94.5%\t22.9M\t81\t109.4\t8.1\n",
    "- VGG16\t528\t71.3%\t90.1%\t138.4M\t16\t69.5\t4.2\n",
    "- VGG19\t549\t71.3%\t90.0%\t143.7M\t19\t84.8\t4.4\n",
    "- ResNet50\t98\t74.9%\t92.1%\t25.6M\t107\t58.2\t4.6\n",
    "- ResNet50V2\t98\t76.0%\t93.0%\t25.6M\t103\t45.6\t4.4\n",
    "- ResNet101\t171\t76.4%\t92.8%\t44.7M\t209\t89.6\t5.2\n",
    "- ResNet101V2\t171\t77.2%\t93.8%\t44.7M\t205\t72.7\t5.4\n",
    "- ResNet152\t232\t76.6%\t93.1%\t60.4M\t311\t127.4\t6.5\n",
    "- ResNet152V2\t232\t78.0%\t94.2%\t60.4M\t307\t107.5\t6.6\n",
    "- InceptionV3\t92\t77.9%\t93.7%\t23.9M\t189\t42.2\t6.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7441f4d3",
   "metadata": {},
   "source": [
    "# ConvNet Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f74fb925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9afa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = googlenet(WIDTH, HEIGHT, 3, LR, output=29, model_name=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6d4f3c98",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-7380698e692e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWIDTH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mHEIGHT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m29\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMODEL_NAME\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-39-d948a5e5d680>\u001b[0m in \u001b[0;36mresnext\u001b[1;34m(width, height, frame_count, lr, output, model_name)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'input'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtflearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregularizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'L2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtflearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresnext_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtflearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresnext_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdownsample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtflearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresnext_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'n' is not defined"
     ]
    }
   ],
   "source": [
    "model = resnext(WIDTH, HEIGHT, 3, LR, output=29, model_name=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ac97baca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d,avg_pool_2d, conv_3d, max_pool_3d, avg_pool_3d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "from tflearn.layers.normalization import local_response_normalization\n",
    "from tflearn.layers.merge_ops import merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0722796d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnext(width, height, frame_count, lr, output=9, model_name = 'sentnet_color.model'):\n",
    "    net = input_data(shape=[None, width, height, 3], name='input')\n",
    "    net = tflearn.conv_2d(net, 16, 3, regularizer='L2', weight_decay=0.0001)\n",
    "    net = tflearn.layers.conv.resnext_block(net, n, 16, 32)\n",
    "    net = tflearn.resnext_block(net, 1, 32, 32, downsample=True)\n",
    "    net = tflearn.resnext_block(net, n-1, 32, 32)\n",
    "    net = tflearn.resnext_block(net, 1, 64, 32, downsample=True)\n",
    "    net = tflearn.resnext_block(net, n-1, 64, 32)\n",
    "    net = tflearn.batch_normalization(net)\n",
    "    net = tflearn.activation(net, 'relu')\n",
    "    net = tflearn.global_avg_pool(net)\n",
    "    # Regression\n",
    "    net = tflearn.fully_connected(net, output, activation='softmax')\n",
    "    opt = tflearn.Momentum(0.1, lr_decay=0.1, decay_step=32000, staircase=True)\n",
    "    net = tflearn.regression(net, optimizer=opt,\n",
    "                             loss='categorical_crossentropy')\n",
    "\n",
    "    model = tflearn.DNN(net,\n",
    "                        max_checkpoints=0, tensorboard_verbose=0, tensorboard_dir='log')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c061ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pygta5)",
   "language": "python",
   "name": "pygta5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
